{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenh/.conda/envs/advTexture/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:4\")\n",
    "    print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:04:00.070124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 09:04:00.447478: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-17 09:04:01.550018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-17 09:04:01.550306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-17 09:04:01.550331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import os \n",
    "import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Utils import *\n",
    "from Models import *\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2670, 3, 32, 32)\n",
      "(7, 2670, 3, 32, 32)\n",
      "(2670,)\n",
      "(2670,)\n"
     ]
    }
   ],
   "source": [
    "Mean_Images = sio.loadmat(\"Sample Data/images.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Mean_Images)) \n",
    "Images = sio.loadmat(\"Sample Data/images_time.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Images)) \n",
    "Label = (sio.loadmat(\"Sample Data/FeatureMat_timeWin\")[\"features\"][:,-1]-1).astype(int) #corresponding to the signal label (i.e. load levels). 0,1,2,3\n",
    "print(np.shape(Label)) \n",
    "Patient_id = sio.loadmat(\"Sample Data/trials_subNums.mat\")['subjectNum'][0] #corresponding to the patient id\n",
    "print(np.shape(Patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose among the patient : [ 1  2  3  4  6  7  8  9 10 11 12 14 15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose among the patient : \"+str(np.unique(Patient_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_patient = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_epoch = 30\n",
    "n_rep = 20  # 记录20次重复实验的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Confusion_Test_Model(net, Testloader, criterion, is_cuda=True):\n",
    "    running_loss = 0.0 \n",
    "    evaluation = []\n",
    "    predicted_label = []\n",
    "    true_label = []\n",
    "    for i, data in enumerate(Testloader, 0):\n",
    "        input_img, labels = data\n",
    "        input_img = input_img.to(torch.float32)\n",
    "        if is_cuda:\n",
    "            input_img = input_img.cuda()\n",
    "        outputs = net(input_img)\n",
    "        _, predicted = torch.max(outputs.cpu().data, 1)\n",
    "        predicted_label += predicted.cpu().data.tolist()\n",
    "        true_label += labels.tolist()\n",
    "        evaluation.append((predicted==labels).tolist())\n",
    "        loss = criterion(outputs, labels.cuda())\n",
    "        running_loss += loss.item()\n",
    "    running_loss = running_loss/(i+1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    running_acc = sum(evaluation)/len(evaluation)\n",
    "    return running_loss, running_acc, predicted_label, true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_Train_Model(model, trainloader, testloader, n_epoch=30, opti='SGD', learning_rate=0.0001, is_cuda=True, print_epoch =5, verbose=False):\n",
    "    if is_cuda:\n",
    "        net = model().cuda()\n",
    "    else :\n",
    "        net = model()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if opti=='SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "    elif opti =='Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    else: \n",
    "        print(\"Optimizer: \"+optim+\" not implemented.\")\n",
    "\n",
    "\n",
    "    predicted_label = []\n",
    "    true_label = []\n",
    "    max_acc = 0    \n",
    "    for epoch in tqdm.tqdm(range(n_epoch)):\n",
    "        running_loss = 0.0\n",
    "        evaluation = []\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.to(torch.float32).cuda())  # (batch_size, 4)\n",
    "            _, predicted = torch.max(outputs.cpu().data, 1) # 取出4个类别中最大概率对应的索引\n",
    "            evaluation.append((predicted==labels).tolist())\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss = running_loss/(i+1)\n",
    "        evaluation = [item for sublist in evaluation for item in sublist]\n",
    "        running_acc = sum(evaluation)/len(evaluation)\n",
    "        validation_loss, validation_acc, predicted_, true_ = Confusion_Test_Model(net, testloader, criterion,True)\n",
    "        if validation_acc > max_acc:\n",
    "            max_acc = validation_acc\n",
    "            predicted_label = predicted_\n",
    "            true_label = true_\n",
    "\n",
    "\n",
    "        if epoch%print_epoch==(print_epoch-1):\n",
    "            print('[%d, %3d]\\tloss: %.3f\\tAccuracy : %.3f\\t\\tval-loss: %.3f\\tval-Accuracy : %.3f' %\n",
    "             (epoch+1, n_epoch, running_loss, running_acc, validation_loss, validation_acc))\n",
    "    \n",
    "    return (running_loss, running_acc, validation_loss,validation_acc), predicted_label, true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Temp CNN \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:22<00:00,  2.75s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.80s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.79s/it]\n",
      "100%|██████████| 30/30 [01:21<00:00,  2.71s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:21<00:00,  2.73s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n",
      "100%|██████████| 30/30 [01:22<00:00,  2.76s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:22<00:00,  2.74s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n",
      "100%|██████████| 30/30 [01:22<00:00,  2.74s/it]\n",
      "100%|██████████| 30/30 [01:22<00:00,  2.76s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:21<00:00,  2.73s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\\n\\n Temp CNN \\n\\n\\n\\n\")\n",
    "\n",
    "Predict_Label = []\n",
    "True_Label = []\n",
    "Result = []\n",
    "for r in range(n_rep):\n",
    "    label = Label[Patient_id == choosen_patient]    # (185,)\n",
    "    image = Images[:, Patient_id == choosen_patient, :, :]  # (7,185,3,32,32)\n",
    "    image = np.transpose(image, (1, 0, 2, 3, 4))  # (185,7,3,32,32)\n",
    "    EEG = EEGImagesDataset(label=label, image=image)\n",
    "    lengths = [int(len(EEG) * train_part + 1), int(len(EEG) * test_part)]\n",
    "    if sum(lengths) < len(EEG):\n",
    "        lengths[0] = lengths[0] + 1\n",
    "    if sum(lengths) > len(EEG):\n",
    "        lengths[0] = lengths[0] - 1\n",
    "    Train, Test = random_split(EEG, lengths)\n",
    "    Trainloader = DataLoader(Train, batch_size=batch_size)\n",
    "    Testloader = DataLoader(Test, batch_size=batch_size)\n",
    "    res, predicted_, true_ = Confusion_Train_Model(TempCNN, Trainloader, Testloader, n_epoch=n_epoch, learning_rate=0.001, print_epoch=-1,\n",
    "                            opti='Adam')\n",
    "    Result.append(res)\n",
    "    Predict_Label.append(predicted_)\n",
    "    True_Label.append(true_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9743589743589743\n",
      "0.9487179487179487\n",
      "0.9230769230769231\n",
      "0.9743589743589743\n",
      "0.8974358974358975\n",
      "0.9743589743589743\n",
      "0.9743589743589743\n",
      "1.0\n",
      "0.9487179487179487\n",
      "1.0\n",
      "0.9743589743589743\n",
      "0.9743589743589743\n",
      "0.8717948717948718\n",
      "0.9487179487179487\n",
      "1.0\n",
      "0.9487179487179487\n",
      "0.9743589743589743\n",
      "1.0\n",
      "0.9743589743589743\n",
      "0.9487179487179487\n",
      "Mean Accuracy: 0.9615384615384615\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Result)):\n",
    "    print(Result[i][3])\n",
    "\n",
    "print(\"Mean Accuracy: \"+str(np.mean([Result[i][3] for i in range(len(Result))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest accuracy is:  1.0\n",
      "The corresponding confusion matrix is: [[16  0  0  0]\n",
      " [ 0 10  0  0]\n",
      " [ 0  0 11  0]\n",
      " [ 0  0  0  2]]\n",
      "The second largest accuracy is:  0.9743589743589743\n",
      "The third largest accuracy is:  0.9487179487179487\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the largest accuracy among the 20 times\n",
    "max_acc = 0\n",
    "for i in range(len(Result)):\n",
    "    if Result[i][3] > max_acc:\n",
    "        max_acc = Result[i][3]\n",
    "        max_index = i\n",
    "print(\"The largest accuracy is: \", max_acc)\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(True_Label[max_index], Predict_Label[max_index])\n",
    "print(f\"The corresponding confusion matrix is: {cm}\")\n",
    "# 可视化混淆矩阵\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False,\n",
    "            xticklabels=['1','2','3','4'], yticklabels=['1','2','3','4'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "# 保存混淆矩阵为图片文件\n",
    "plt.savefig('ConfusionMatrix.png', dpi=400)\n",
    "\n",
    "# find the second largest accuracy among the 20 times\n",
    "second_max_acc = 0\n",
    "for i in range(len(Result)):\n",
    "    if Result[i][3] > second_max_acc and Result[i][3] < max_acc:\n",
    "        second_max_acc = Result[i][3]\n",
    "        second_max_index = i\n",
    "print(\"The second largest accuracy is: \", second_max_acc)\n",
    "# # 计算混淆矩阵\n",
    "# sec_cm = confusion_matrix(True_Label[second_max_index], Predict_Label[second_max_index])\n",
    "# print(f\"The corresponding confusion matrix is: {sec_cm}\")\n",
    "# # 可视化混淆矩阵\n",
    "# sns.heatmap(sec_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False,\n",
    "#             xticklabels=['1','2','3','4'], yticklabels=['1','2','3','4'])\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# # 保存混淆矩阵为图片文件\n",
    "# plt.savefig('ConfusionMatrix.png', dpi=400)\n",
    "\n",
    "# find the third largest accuracy among the 20 times\n",
    "third_max_acc = 0\n",
    "for i in range(len(Result)):\n",
    "    if Result[i][3] > third_max_acc and Result[i][3] < second_max_acc:\n",
    "        third_max_acc = Result[i][3]\n",
    "        third_max_index = i\n",
    "print(\"The third largest accuracy is: \", third_max_acc)\n",
    "# # 计算混淆矩阵\n",
    "# third_cm = confusion_matrix(True_Label[third_max_index], Predict_Label[third_max_index])\n",
    "# print(f\"The corresponding confusion matrix is: {third_cm}\")\n",
    "# # 可视化混淆矩阵\n",
    "# sns.heatmap(third_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False,\n",
    "#             xticklabels=['1','2','3','4'], yticklabels=['1','2','3','4'])\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# # 保存混淆矩阵为图片文件\n",
    "# plt.savefig('ConfusionMatrix.png', dpi=400)\n",
    "\n",
    "# # find the forth largest accuracy among the 20 times\n",
    "# forth_max_acc = 0\n",
    "# for i in range(len(Result)):\n",
    "#     if Result[i][3] > forth_max_acc and Result[i][3] < third_max_acc:\n",
    "#         forth_max_acc = Result[i][3]\n",
    "#         forth_max_index = i\n",
    "# print(\"The forth largest accuracy is: \", forth_max_acc)\n",
    "# # 计算混淆矩阵\n",
    "# third_cm = confusion_matrix(True_Label[forth_max_index], Predict_Label[forth_max_index])\n",
    "# print(f\"The corresponding confusion matrix is:\\n {third_cm}\")\n",
    "# # 可视化混淆矩阵\n",
    "# sns.heatmap(third_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False,\n",
    "#             xticklabels=['1','2','3','4'], yticklabels=['1','2','3','4'])\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# # 保存混淆矩阵为图片文件\n",
    "# plt.savefig('ConfusionMatrix.png', dpi=400)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advTexture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
